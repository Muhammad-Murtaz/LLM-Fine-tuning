# LLM Fine-Tuning with Llama 3 (Unsloth)

This repository demonstrates efficient fine-tuning of **Llama 3 (8B)** using:
- Unsloth (4-bit quantization)
- LoRA (PEFT)
- TRL SFTTrainer
- Google Colab (T4 GPU)

## Highlights
- Fine-tuning on free GPU
- Parameter-efficient training
- Instruction-following dataset

## Notebook
- llama3_unsloth_finetuning.ipynb

## How to Run
1. Open the notebook in Google Colab
2. Enable GPU (Runtime → Change runtime → T4)
3. Run all cells
